{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from jax import random\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bayesian_active_learning.acquisition_functions import (\n",
    "    get_acquisition_function,\n",
    ")\n",
    "from bayesian_active_learning.experiment import experiment_run\n",
    "from bayesian_active_learning.utils import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following notebook attempts to verify that the BALD acquisition function outperforms random sampling of the pool set, when the pool set has been artificially imbalanced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The original pool set is more or less balanced, since the original MNIST training dataset is well balanced.\n",
    "- However, we artifically introduce class imbalance to the pool set by removing 75% of the 2s present.\n",
    "- Since the BALD score can actively \"target\" the smaller amount of twos in acquisition, we expected it to perform better than random sampling, where we have to \"get lucky\" to come across a two in the acquired points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The notebook produces a figure in `figures/03_modified_pool_set`.\n",
    "- The figure shows that when using a small batch size, using the BALD score outperforms random sampling from the pool, which is closer to the plot shown in the original paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_experiment(acquisition_function_name: str, seed: int) -> jnp.ndarray:\n",
    "    # get acquisition function\n",
    "    acquisition_function = get_acquisition_function(acquisition_function_name)\n",
    "\n",
    "    # grab all datasets + preprocess\n",
    "\n",
    "    full_train_dataset = torchvision.datasets.MNIST(\n",
    "        \"../datasets\", train=True, download=True\n",
    "    )\n",
    "    full_test_dataset = torchvision.datasets.MNIST(\n",
    "        \"../datasets\", train=False, download=True\n",
    "    )\n",
    "\n",
    "    num_classes = len(full_train_dataset.classes)\n",
    "    total_train_samples = len(full_train_dataset.data)\n",
    "    total_test_samples = len(full_train_dataset.data)\n",
    "\n",
    "    all_train_X = np.array(full_train_dataset.data) / 255.0\n",
    "    all_train_y = one_hot(np.array(full_train_dataset.targets), k=num_classes)\n",
    "\n",
    "    all_test_X = np.array(full_test_dataset.data) / 255.0\n",
    "    all_test_y = one_hot(np.array(full_test_dataset.targets), k=num_classes)\n",
    "\n",
    "    # shuffle the datasets according to the seed and split into initial train, test and pool sets\n",
    "    num_initial_train_points = 100\n",
    "    num_validation_points = 100\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shuffle_idx = rng.permutation(len(all_train_X))\n",
    "\n",
    "    all_train_X, all_train_y = all_train_X[shuffle_idx], all_train_y[shuffle_idx]\n",
    "\n",
    "    initial_train_X, val_X, initial_pool_X = np.split(\n",
    "        all_train_X,\n",
    "        [num_initial_train_points, num_initial_train_points + num_validation_points],\n",
    "    )\n",
    "    initial_train_y, val_y, initial_pool_y = np.split(\n",
    "        all_train_y,\n",
    "        [num_initial_train_points, num_initial_train_points + num_validation_points],\n",
    "    )\n",
    "\n",
    "    # perform class based subsampling of pool set\n",
    "    key = random.PRNGKey(seed)\n",
    "\n",
    "    two_label = jnp.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "    two_mask = (initial_pool_y @ two_label).astype(bool)\n",
    "\n",
    "    pool_twos = initial_pool_X[two_mask]\n",
    "    num_twos = len(pool_twos)\n",
    "\n",
    "    pool_X_removed_twos = initial_pool_X[~two_mask]\n",
    "    pool_y_removed_twos = initial_pool_y[~two_mask]\n",
    "\n",
    "    # subsample a proportion of the pool of twos and labels\n",
    "    key = random.PRNGKey(0)\n",
    "    key, subkey = random.split(key, 2)\n",
    "    subsampling_idxs = random.choice(\n",
    "        subkey, np.arange(num_twos), (int(num_twos * 0.25),), replace=False\n",
    "    )\n",
    "\n",
    "    subsampled_pool_twos = pool_twos[subsampling_idxs]\n",
    "    subsampled_pool_twos_labels = np.stack([two_label] * num_twos)\n",
    "\n",
    "    # reintroduce into pool\n",
    "    new_pool_X = np.concatenate([pool_X_removed_twos, subsampled_pool_twos])\n",
    "    new_pool_y = np.concatenate([pool_y_removed_twos, subsampled_pool_twos_labels])\n",
    "\n",
    "    # shuffle pool\n",
    "    key, subkey = random.split(key, 2)\n",
    "    shuffle_idx = random.permutation(subkey, np.arange(len(new_pool_X)))\n",
    "\n",
    "    new_pool_X = new_pool_X[shuffle_idx]\n",
    "    new_pool_y = new_pool_y[shuffle_idx]\n",
    "\n",
    "    # run the active learning procedure with the acquisition function and datasets\n",
    "    test_accuracy_history = experiment_run(\n",
    "        train_set=(initial_train_X, initial_train_y),\n",
    "        val_set=(val_X, val_y),\n",
    "        pool_set=(new_pool_X, new_pool_y),\n",
    "        test_set=(all_test_X, all_test_y),\n",
    "        weight_decay=1e-2,\n",
    "        acquisition_fn=acquisition_function,\n",
    "        num_predictive_samples=100,\n",
    "        num_acquired_points_per_iteration=100,\n",
    "        num_iterations=5,\n",
    "        key=key,\n",
    "    )\n",
    "\n",
    "    return test_accuracy_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_functions = [\"BALD\", \"Random\"]\n",
    "seeds = np.arange(6)\n",
    "\n",
    "param_grid = {\"acquisition_function_name\": acquisition_functions, \"seed\": seeds}\n",
    "arg_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for args in tqdm(arg_list):\n",
    "    results.append(full_experiment(**args))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_results = {af: [] for af in acquisition_functions}\n",
    "\n",
    "for result, arg in zip(results, arg_list):\n",
    "    grouped_results[arg[\"acquisition_function_name\"]].append(result)\n",
    "\n",
    "grouped_results = {af: jnp.stack(r) for af, r in grouped_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, results in grouped_results.items():\n",
    "    median = 100 * np.median(results, axis=0)\n",
    "    lower_quartile = 100 * np.percentile(results, 25, axis=0)\n",
    "    upper_quartile = 100 * np.percentile(results, 75, axis=0)\n",
    "\n",
    "    plt.plot(100 * np.arange(len(median)), median, label=label)\n",
    "    plt.fill_between(\n",
    "        100 * np.arange(len(median)), lower_quartile, upper_quartile, alpha=0.25\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Number of acquired points\")\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.ylim(75, 100)\n",
    "plt.legend()\n",
    "plt.savefig(\"../figures/03_modified_pool_set/plot.png\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
