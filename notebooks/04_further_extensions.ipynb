{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imbalanced test set distribution\n",
    "*Maximising predictive performance* using BALD worked well when the test set was balanced. However, we didn't test out the case where the *test set* is imbalanced, where a different acquisition function might have been more appropriate. \n",
    "It would be interesting to follow one of the lines of work presented by [Test Distributionâ€“Aware Active Learning:\n",
    "A Principled Approach Against Distribution Shift and Outliers](https://arxiv.org/pdf/2106.11719.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Artificially increasing aleatoric uncertainty in the pool set to highlight the performance difference between the `max entropy` and `BALD` acquisition functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BALD score is a way of acquiring labelled datapoints that have high *epistemic* uncertainty. Choosing the points with the highest entropy over the posterior predictive distribution conflates *aleatoric* and epistemic uncertainty, meaning that we can also choose points with high irreducible noise (unhelpfully) which don't improve predictive performance, rather than just ones with high predictive uncertainty due to lack of knowledge of model parameters. We didn't really notice this in the experiment, (probably because there aren't that many points that can be truly labelled as one of two or more digits) but we could upsample the pool set with cases like this, to see if we can show the intuition behind the two measures of uncertainty experimentally."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesian active learning in other contexts (Preferential Bayesian Optimization/reinforcement learning from human feedback)\n",
    "\n",
    "There is a paper on the concept of [Preferential Bayesian Optimization](https://arxiv.org/abs/1704.03651), which showcases an sample efficient querying algorithm to find the optimum of a black box function, only given access the outcomes of \"duels\", which give the preference between two different inputs passed into the function. However, one aspect of the algorithm is to select one half of the duel that maximises the predictive entropy of the distribution over the outcome of the duel. A more appropriate acquisition function in this case would be the BALD score, for reasons given above, particularly if the black box function has a large amount of irreducible uncertainty (which is often the case if a human is giving preferences).\n",
    "\n",
    "I think a similar argument can be made for efficient reward modelling in reinforcement learning from human feedback, in the context of aligning large language models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
